{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2911b734-67be-4259-9bba-a9ff8efe0c01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 00 - Environment Setup\n",
    "\n",
    "Se presenta a continuación el \"notebook\" para desarrollar el proyecto de Grupo 3 de la materia Sistemas en la Nube PAO 1 2024 ESPOL. \n",
    "\n",
    "\"Sistema de aprendizaje automático para la detección temprana y precisa de enfermedades fúngicas en cultivos de papa, fresa y cereza en la sierra de Ecuador\". \n",
    "\n",
    "Integrantes:\n",
    "- Jara Yupa Ana Belén\n",
    "- Rengifo Barciona Pedro Francisco\n",
    "- Quizhpi Torres Beatriz Aurora\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee7178",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "En esta sección se realizan pre-requisitos para desarrollar el proyecto, tales como variables globales, importar librerias y activar los clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80aba5e",
   "metadata": {},
   "source": [
    "Obtener Nombre Mi Proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f9ee4d-62f2-473f-b9ea-61212bf9074e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grupo03-ml00'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0567c50-9ab4-4e62-ba8f-08a3d4283d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Establecer la región de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c342aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632bae5a",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d470506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d354569f-5abf-4ba2-a6e0-60de4aad8efe",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a75b04c-3632-4d1f-a4ae-0e80b556de99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728c71d",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c5eb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ade2ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 1. Crear Bucket de Almacenamiento\n",
    "Inicialmente revisa si está creado, y si no lo crea:\n",
    "- [GCS Python Client](https://cloud.google.com/python/docs/reference/storage/latest/google.cloud.storage.client.Client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa83e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Bucket: grupo03-ml00\n"
     ]
    }
   ],
   "source": [
    "if not gcs.lookup_bucket(BUCKET):\n",
    "    bucketDef = gcs.bucket(BUCKET)\n",
    "    bucket = gcs.create_bucket(bucketDef, project=PROJECT_ID, location=REGION)\n",
    "    print(f'Created Bucket: {gcs.lookup_bucket(BUCKET).name}')\n",
    "else:\n",
    "    bucketDef = gcs.bucket(BUCKET)\n",
    "    print(f'Bucket already exist: {bucketDef.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "414f3fbc-baa6-442b-a36d-d39ce4659061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revisar el bucket creado aqui:\n",
      "https://console.cloud.google.com/storage/browser/grupo03-ml00;tab=objects&project=grupo03-ml00\n"
     ]
    }
   ],
   "source": [
    "print(f'Revisar el bucket creado aqui:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID};tab=objects&project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c7290-cfd1-4022-a524-c20a123aa22d",
   "metadata": {},
   "source": [
    "---\n",
    "<a id = 'permissions'></a>\n",
    "## 2. Service Account & Permissions\n",
    "\n",
    "Esta instancia de notebook se ejecuta como una cuenta de servicio en GCP. Esta cuenta de servicio también se utilizará para ejecutar otros servicios en Vertex AI, como training jobs y pipelines. La cuenta de servicio necesitará permiso para interactuar con el objeto en Cloud Storage que requiere la función.([roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles)).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a4b97-822b-46cc-84ca-5df97359b639",
   "metadata": {},
   "source": [
    "Get the current service account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ecb20b-a16b-460f-88e6-bb4866686cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'646324389573-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660fa4ec-fed9-4868-953c-0bd8d0118c22",
   "metadata": {},
   "source": [
    "Enable the Cloud Resource Manager API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53429ebb-ab4e-4d23-bd10-6fa3902feaf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable cloudresourcemanager.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c325662-bf04-423d-8ad0-ee9022819b20",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d35738-e529-4c47-b2dd-f653bcc85af8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/editor\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82db371-3788-4d25-9046-1df31f535e09",
   "metadata": {},
   "source": [
    "Si en la lista resultante falta `roles/storage.objectAdmin` u otra función que contenga este permiso, como la función básica `roles/owner`, entonces será necesario agregarlo para la cuenta de servicio. Utilice estas instrucciones para completar los roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b868873-7217-49b9-9b13-31059da50a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go To IAM in the Google Cloud Console:\n",
      "https://console.cloud.google.com/iam-admin/iam?orgonly=true&project=statmike-mlops-349915&supportedpurview=organizationId\n"
     ]
    }
   ],
   "source": [
    "print(f'Go To IAM in the Google Cloud Console:\\nhttps://console.cloud.google.com/iam-admin/iam?orgonly=true&project={PROJECT_ID}&supportedpurview=organizationId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51482d76-ceed-496c-bed8-1f1ea875a92e",
   "metadata": {},
   "source": [
    "Desde el enlace de la consola anterior, o accediendo a https:/console.cloud.google.com y navegando a \"IAM y administrador > IAM\":\n",
    "- Localice la fila de la cuenta de servicio que aparece arriba: `<número de proyecto>-compute@developer.gserviceaccount.com`\n",
    "- Debajo de la columna \"herencia\", haga clic en el ícono de lápiz para editar roles\n",
    "- En el menú desplegable, en \"Asignar roles\", seleccione \"Agregar otro rol\".\n",
    "- Haga clic en el cuadro \"Seleccionar una función\" y escriba \"Administrador de objetos de almacenamiento\", luego seleccione \"Administrador de objetos de almacenamiento\".\n",
    "- Haga clic en Guardar\n",
    "- Vuelva a ejecutar la lista de servicios a continuación y verifique que se haya agregado la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82eeadef-20e6-4666-bff7-2d66e431f17a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/bigquery.admin\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa510f-89ea-425b-9f8b-879313495f9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## OPCIONAL Cargar data al bucket desde Github (code)\n",
    "Tambien existe la opción de insertar directamente al bucket, la solución a continuacion se plantea mediante un repositorio en github.\n",
    "Creará la carpeta y copiara los archivos desde el repositorio, este proceso requerira tiempo ya que el data consiste en 3 plantas: \"potato\", \"strawberry\" y \"cherry\" con un total de 5623 imagenes. La data se obtuvo de kaggle y de ahi se selecciono 3 plantas para minimizar el procesamiento \n",
    "Fuente Kaggle PlantVillageDiseased https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3c3a777-660a-42cc-a439-397c5eb46dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "github_repo = 'pfrengifob/SN_2024PAO1'\n",
    "github_path = 'data'\n",
    "gcs_data_folder = 'data'\n",
    "csv_file_path = 'vegeCsv.csv'  # Ruta en el entorno de Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0e329ac-5404-4269-b6b1-71792486f1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac63f4a9-213e-4822-a2e2-cdacb190afd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funcion Listar archivos de github recursivamente\n",
    "def list_github_files(repo, path):\n",
    "    url = f'https://api.github.com/repos/{repo}/contents/{path}'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    contents = response.json()\n",
    "    \n",
    "    files = []\n",
    "    for content in contents:\n",
    "        if content['type'] == 'file' and content['name'].lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "            files.append(content)\n",
    "        elif content['type'] == 'dir':\n",
    "            files.extend(list_github_files(repo, content['path']))\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8e65947-a2a5-4beb-bb9f-37b7a676ba5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funcion para descargar los archivos y subirlos al bucket de GCS (GoogleCloudStorage)\n",
    "def download_and_upload_file(bucket_name, github_file, gcs_folder):\n",
    "    file_url = github_file['download_url']\n",
    "    file_path = github_file['path']\n",
    "    local_path = os.path.join('/tmp', os.path.basename(file_path))\n",
    "    \n",
    "    # Descargar Archivo\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "    with open(local_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Subir Archivo a GCS\n",
    "    gcs_path = file_path.replace(\"\\\\\", \"/\")  # Emplea Misma Ruta que Github\n",
    "    bucket = gcs.bucket(bucket_name)\n",
    "    blob = bucket.blob(gcs_path)\n",
    "    blob.upload_from_filename(local_path)\n",
    "    print(f'Uploaded {local_path} to gs://{bucket_name}/{gcs_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a75f2b50-9ae1-4fae-99bd-80eece573ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Llamar a listar archivos de Github\n",
    "github_files = list_github_files(github_repo, github_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2f074-6d48-4401-a737-91cff169b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar y cargar cada archivo siguiendo la misma estructura\n",
    "for github_file in github_files:\n",
    "    download_and_upload_file(BUCKET, github_file, gcs_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511d3b6-1d45-4eb4-97d3-ba3efd2cca8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Preparar Data\n",
    "Se requiere preparar datos de entrenamiento de imágenes para usarlos en un conjunto de datos de Vertex AI a fin de entrenar un modelo de clasificación de imágenes. Para ello hay que seguir la estructura que indican en la documentación: https://cloud.google.com/vertex-ai/docs/image-data/classification/prepare-data?hl=es-419#csv\n",
    "\n",
    "Se empleará el formata csv con las columnas [ML_USE],GCS_FILE_PATH,[LABEL]\n",
    "\n",
    "Lista de columnas\n",
    "\n",
    "ML_USE (opcional): Para fines de división de datos durante el entrenamiento de un modelo. Usa TRAINING, TEST o VALIDATION. En este proyecto se considera el 80% para Training, 10% Test y 10% Validation.\n",
    "\n",
    "GCS_FILE_PATH: este campo contiene el URI de Cloud Storage para la imagen. Los URI de Cloud Storage distinguen entre mayúsculas y minúsculas.\n",
    "\n",
    "LABEL (opcional): las etiquetas deben comenzar con una letra y solo deben contener letras, números y guiones bajos.\n",
    "Ejemplo de CSV: image_classification_single_label.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebf31d49-be06-438d-bd2b-1a69ee218d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7389789-0f13-4b62-9346-4d67c6ffcb81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funcion Listar imagenes de GoogleCloudStorage y obetener URIs\n",
    "def list_images_in_gcs(bucket_name, gcs_folder):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=gcs_folder)\n",
    "    \n",
    "    gcs_uris = []\n",
    "    for blob in blobs:\n",
    "        if blob.name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "            label = blob.name.split('/')[-2]  # Assuming the label is the parent folder name\n",
    "            gcs_uri = f'gs://{bucket_name}/{blob.name}'\n",
    "            gcs_uris.append((gcs_uri, label))\n",
    "            print(f'Found {gcs_uri} with label {label}')\n",
    "    \n",
    "    return gcs_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e311b1c-1412-45a9-8442-ab24e0d295e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funcion Generar csv a partir de URIs\n",
    "def generate_csv_from_gcs_uris(gcs_uris, csv_file_path):\n",
    "    # Mezclar la lista\n",
    "    random.shuffle(gcs_uris)\n",
    "    \n",
    "    # Split \n",
    "    train_split = int(0.8 * len(gcs_uris))\n",
    "    val_split = int(0.9 * len(gcs_uris))\n",
    "    \n",
    "    train_uris = gcs_uris[:train_split]\n",
    "    val_uris = gcs_uris[train_split:val_split]\n",
    "    test_uris = gcs_uris[val_split:]\n",
    "    \n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['ML_USE', 'GCS_FILE_PATH', 'LABEL'])\n",
    "        \n",
    "        for gcs_uri, label in train_uris:\n",
    "            writer.writerow(['training', gcs_uri, label])\n",
    "        \n",
    "        for gcs_uri, label in val_uris:\n",
    "            writer.writerow(['validation', gcs_uri, label])\n",
    "        \n",
    "        for gcs_uri, label in test_uris:\n",
    "            writer.writerow(['test', gcs_uri, label])\n",
    "    \n",
    "    print(f'CSV file created at {csv_file_path} with {len(gcs_uris)} images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d37ce-b0dd-4773-bb4d-38302af8e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la funcion listar imagenes\n",
    "gcs_uris = list_images_in_gcs(BUCKET, gcs_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c70425a-b361-4ae8-a4ef-65baba1f9fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at vegeCsv.csv with 5462 images.\n"
     ]
    }
   ],
   "source": [
    "# Generar csv\n",
    "generate_csv_from_gcs_uris(gcs_uris, csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75f121-a285-4844-8800-24a77c262f96",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cargar Dataset (Consola)\n",
    "A continuación se aprovecha la interfaz de GCP y se carga el respectivo .CSV en la mismo ubicacion donde se encuentre nuestro bucket (Desplegamos Menú Navegación de Apis, buscamos Cloud Storage y seleccionamos Buckets). \n",
    "De esta manera no habrá conflicto para realizar lectura de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33964dbc-09e6-44a4-85a6-90d2bee86f07",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![CSV Bucket](./imagenes/csvBucket.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7848c68b-a13f-4c50-8ec8-6ec5c2cb3d08",
   "metadata": {},
   "source": [
    "Posteriormente se crea el conjunto de datos en Vertex AI (Desplagamos Menú Izquierda - Vertex AI Api - Data - Conjunto de Datos). Se selecciona Clasificación con varias etiquetas y la misma región que estamos desarrollando. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d90d8-ee9a-4696-b8e6-be0f3cef4d94",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "![CSV Bucket](./imagenes/plantDataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f333f18-bdb8-4a1c-9b1b-a9613a9beae0",
   "metadata": {},
   "source": [
    "Se procede a dar click en el dataset creado e importamos el csv indicando la ruta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e018f8-56ba-484a-b07c-bb6a6d1f6968",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![CSV Bucket](./imagenes/plantDataset2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36e5c1-b87f-45fb-aecf-031bed4b9c01",
   "metadata": {},
   "source": [
    "Este proceso requiere unos minutos y una vez culminado tendremos un breve resumen de nuestros datos etiquetados listos para entrenar, además de la cantidad para entrenamiento, validación y test, tal como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5893d7c-6ac4-413c-8069-2bb971cb30dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./imagenes/plantDataset3.png\" alt=\"CSV Bucket 1\" style=\"margin-right: 10px; width: 400px;\"/>\n",
    "    <img src=\"./imagenes/plantDataset4.png\" alt=\"width: 300px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93df437-662b-4e76-87e1-90a70ef305cd",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Entrenar Modelo e Implementar en el Extremo (Consola)\n",
    "Con nuestro dataset listo, se emplea AutoML como modelo de gran calidad y minimo esfuerzo de machine learning, además se especifican la cantidad de nodos (9 por hora) para el entrenamiento. Para ello en la misma sección del paso previo, se selecciona \"Entrenar Nuevo Modelo\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e641363b-c5bd-47e4-8ebb-542c57c45ea4",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "![CSV Bucket](./imagenes/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11232d-d8dc-42b6-9092-cc8216b8a07f",
   "metadata": {},
   "source": [
    "El entrenamiento dependerá de la cantidad de nodos asignados y una vez culminado notificará por correo, para este proyecto demoró 1 hora y 48 minutos con 9 nodos. Adicionalmente se puede apreciar detalles del modelo y estadísticas como la evaluación realizada, la precisión y el limite de confianza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47de03-3f63-43de-9394-a04f8feec2ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "![CSV Bucket](./imagenes/training2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838887a-9512-4b8f-8ab2-2598188d9560",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "![CSV Bucket](./imagenes/training3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39322130-a471-4fe2-b96c-1a2b4b1b49cc",
   "metadata": {},
   "source": [
    "Finalmente, en la seccion \"Deploy And Use\" de Vertex AI, seleccionamos Prediccion en linea y creamos un \"Extremo\" con un nodo de procesamiento. El Endpoint nos permitira realizar peticiones ya sea en la plataforma, mediante Rest o Python, de esa manera se logrará predecir el estado del vegetal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d47b3-9535-495c-94d5-7b619825c1f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "![CSV Bucket](./imagenes/endpoint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca543663-d098-4a68-bdc9-8068d5875dd5",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Predicciones\n",
    "Una vez implementado con exito el modelo de deteccion de estado de fresas, cerezas y papas, a partir de peticiones en Rest o Python se pueden realizar distintos ensayos para simular en un entorno real.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50baaf5-e51d-4902-b459-23f778915077",
   "metadata": {},
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63da520a-f0ff-4af3-9234-19772993a83f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "337a2d6b-b2f4-4aa1-a036-7ad31f63f409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Funcion predecir imagenes \n",
    "def predict_image_classification_sample(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    filename: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    \n",
    "    # Read the image file\n",
    "    with open(filename, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # Encode the image content\n",
    "    encoded_content = base64.b64encode(file_content).decode(\"utf-8\")\n",
    "    instance = predict.instance.ImageClassificationPredictionInstance(\n",
    "        content=encoded_content,\n",
    "    ).to_value()\n",
    "    instances = [instance]\n",
    "    \n",
    "    # Set the parameters for the prediction\n",
    "    parameters = predict.params.ImageClassificationPredictionParams(\n",
    "        confidence_threshold=0.5,\n",
    "        max_predictions=5,\n",
    "    ).to_value()\n",
    "    \n",
    "    # Get the endpoint path\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    \n",
    "    # Make the prediction request\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    \n",
    "    # Print the response\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "    \n",
    "    # Print the predictions\n",
    "    predictions = response.predictions\n",
    "    for prediction in predictions:\n",
    "        print(\" prediction:\", dict(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9dbc2f4-4ceb-41dd-a4d4-704317ee8253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      " deployed_model_id: 8142166178169618432\n",
      " prediction: {'displayNames': ['Cherry_(including_sour)___Powdery_mildew'], 'confidences': [0.934258], 'ids': ['8748327213440434176']}\n"
     ]
    }
   ],
   "source": [
    "#Llamar a predecir cherry\n",
    "predict_image_classification_sample(\n",
    "    project=\"646324389573\",\n",
    "    endpoint_id=\"5497207394670739456\",\n",
    "    filename=\"./imageTest/cherry3.JPG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0c42c-0dbd-4592-a4f6-b778871279de",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "![CSV Bucket](./imageTest/cherry3.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d19e229-ea26-4bdd-9508-d783d02bb3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      " deployed_model_id: 8142166178169618432\n",
      " prediction: {'displayNames': ['Potato___healthy'], 'confidences': [0.985289335], 'ids': ['1830798185799352320']}\n"
     ]
    }
   ],
   "source": [
    "#Llamar a predecir potato\n",
    "predict_image_classification_sample(\n",
    "    project=\"646324389573\",\n",
    "    endpoint_id=\"5497207394670739456\",\n",
    "    filename=\"./imageTest/potato4.JPG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef0d66-3743-442f-9637-8835b3b24453",
   "metadata": {
    "tags": []
   },
   "source": [
    "![CSV Bucket](./imageTest/potato4.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92328612-64c3-4bf7-8445-6c233a59f30b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      " deployed_model_id: 8142166178169618432\n",
      " prediction: {'displayNames': ['Strawberry___Leaf_scorch'], 'ids': ['389646305040793600'], 'confidences': [0.908504546]}\n"
     ]
    }
   ],
   "source": [
    "#Llamar a predecir strawberry\n",
    "predict_image_classification_sample(\n",
    "    project=\"646324389573\",\n",
    "    endpoint_id=\"5497207394670739456\",\n",
    "    filename=\"./imageTest/strawberry2.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5da80-3acf-4851-9e41-5d68dfcf5c37",
   "metadata": {
    "tags": []
   },
   "source": [
    "![CSV Bucket](./imageTest/strawberry2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f446b5f-423b-4e24-b2d8-f0a2db2c6856",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 7. Resultados\n",
    "Se logró predecir con gran porcentaje de aceptación en los 3 distintos ensayos con más de 90% de certeza el estado de la planta, además de identificar su tipo (frambuesas, papas y cerezas). \n",
    "Además, se logró usar predicciones en línea por medio de Python y Jupyter incorporados como clientes de Google Cloud Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619ac23-b886-4956-83b4-301a3dc558df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-6:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
